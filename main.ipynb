{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8c08af",
   "metadata": {},
   "source": [
    "### Generating image embeddings\n",
    "\n",
    "Neural Network: https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html\n",
    "\n",
    "Dataset: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
    "\n",
    "Similarity search using FAISS: https://github.com/facebookresearch/faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f971371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_datasets\n",
    "# !pip install --user efficientnet\n",
    "# !conda install -c pytorch faiss-cpu\n",
    "# !pip install -q ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfeaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_datasets.core import features as features_lib\n",
    "from tensorflow_datasets.core import dataset_utils\n",
    "\n",
    "from efficientnet.preprocessing import center_crop_and_resize\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import faiss\n",
    "\n",
    "import IPython  \n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, HBox, VBox\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_save_images(dataset='tf_flowers', output_folder='./images', images_count=1000, num_examples=30):\n",
    "    # fetch dataset\n",
    "    ds, ds_info = tfds.load('tf_flowers', split=\"train\", with_info=True)\n",
    "    print(ds_info)\n",
    "\n",
    "    # create the output folder \n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # get image and label key\n",
    "    image_keys = [k for k,feature in ds_info.features.items() if isinstance(feature, features_lib.Image)]\n",
    "    image_key = image_keys[0] if len(image_keys) == 1 else None\n",
    "\n",
    "    label_keys = [k for k, feature in ds_info.features.items() if isinstance(feature, features_lib.ClassLabel)]\n",
    "    label_key = label_keys[0] if len(label_keys) == 1 else None\n",
    "\n",
    "    # save some sample images \n",
    "    examples = list(dataset_utils.as_numpy(ds.take(num_examples)))\n",
    "\n",
    "    for i, ex in enumerate(examples):\n",
    "        # get image data from the dict\n",
    "        image = ex[image_key]\n",
    "        if len(image.shape) != 3:\n",
    "            raise ValueError(\"Image dimension should be 3. tfds.show_examples does not support batched examples.\")\n",
    "\n",
    "        _, _, c = image.shape    \n",
    "        if c == 1:\n",
    "            image = image.reshape(image.shape[:2])\n",
    "\n",
    "        image = center_crop_and_resize(image, 224).astype(np.uint8)\n",
    "        im = Image.fromarray(image)\n",
    "\n",
    "        if label_key:\n",
    "            label = ex[label_key]\n",
    "            label_str = ds_info.features[label_key].int2str(label).replace(\"/\", \"_\")\n",
    "        else:\n",
    "            label_str = \"\"\n",
    "\n",
    "        # save the image    \n",
    "        im.save(f\"{output_folder}/image_{label_str}_{i}.jpeg\")\n",
    "        \n",
    "    return ds_info, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ac9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info, ds = fetch_save_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd6f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd7ce9f",
   "metadata": {},
   "source": [
    "#### Write images to tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(images_path):\n",
    "    return tf.data.Dataset.list_files(images_path + '/*', shuffle=False).cache()\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_example(image, image_name):\n",
    "    feature = {\n",
    "        'image_name': _bytes_feature(image_name),\n",
    "        'image': _bytes_feature(image)\n",
    "    }\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def tf_serialize_example(image, image_name):\n",
    "    tf_string = tf.py_function(serialize_example, (image, image_name), tf.string)\n",
    "    return tf.reshape(tf_string, ())\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    parts = tf.strings.split(file_path, '/')\n",
    "    image_name = tf.strings.split(parts[-1], '.')[0]\n",
    "    raw = tf.io.read_file(file_path)\n",
    "    return raw, image_name\n",
    "\n",
    "\n",
    "def read_image_file_write_tfrecord(files_ds, output_filename):\n",
    "    image_ds = files_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    serialized_features_dataset = image_ds.map(tf_serialize_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    writer = tf.data.experimental.TFRecordWriter(output_filename)\n",
    "    # writer = tf.io.TFRecordWriter(output_filename)\n",
    "    writer.write(serialized_features_dataset)\n",
    "\n",
    "    \n",
    "def image_files_to_tfrecords(list_ds, output_folder, num_shard):\n",
    "    start = time.time()\n",
    "    for shard_id in range(0, num_shard):\n",
    "        shard_list = list_ds.shard(num_shards=num_shard, index=shard_id)\n",
    "        output_filename = output_folder + \"/part-\" + \"{:03d}\".format(shard_id) + \".tfrecord\"\n",
    "        read_image_file_write_tfrecord(shard_list, output_filename)\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(time.time() - start)) + \"s\")\n",
    "        \n",
    "\n",
    "def write_tfrecord(image_folder, output_folder, num_shard=100):\n",
    "    list_ds = list_files(image_folder)\n",
    "    image_files_to_tfrecords(list_ds, output_folder, num_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"images\"\n",
    "output_folder = \"tfrecords\"\n",
    "\n",
    "write_tfrecord(image_folder, output_folder, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60977a",
   "metadata": {},
   "source": [
    "#### Read tfrecords, generate embeddings, and write them in parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d939e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "\n",
    "def preprocess_image(d):\n",
    "    image_name = d['image_name']\n",
    "    raw = d['image']\n",
    "    image = tf.image.decode_jpeg(raw)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    return image, image_name\n",
    "\n",
    "\n",
    "def read_tfrecord(filename):\n",
    "    filenames = [filename]\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    return raw_dataset \\\n",
    "        .map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "        .map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "        .apply(tf.data.experimental.ignore_errors())\n",
    "\n",
    "\n",
    "def images_to_embeddings(model, dataset, batch_size):\n",
    "    return model.predict(dataset.batch(batch_size).map(lambda image_raw, image_name: image_raw), verbose=1)\n",
    "\n",
    "\n",
    "def save_embeddings_ds_to_parquet(embeddings, dataset, path):\n",
    "    embeddings = pa.array(embeddings.tolist(), type=pa.list_(pa.float32()))\n",
    "    image_names = pa.array(dataset.map(lambda image_raw, image_name: image_name).as_numpy_iterator())\n",
    "    table = pa.Table.from_arrays([image_names, embeddings], [\"image_name\", \"embedding\"])\n",
    "    pq.write_table(table, path)\n",
    "    \n",
    "\n",
    "def tfrecords_to_write_embeddings(tfrecords_folder, output_folder, model, batch_size):\n",
    "    tfrecords = [f.numpy().decode(\"utf-8\") for f in tf.data.Dataset.list_files(tfrecords_folder + \"/*.tfrecord\", shuffle=False)]\n",
    "    \n",
    "    start = time.time()\n",
    "    for shard_id, tfrecord in enumerate(tfrecords):\n",
    "        shard = read_tfrecord(tfrecord)\n",
    "        embeddings = images_to_embeddings(model, shard, batch_size)\n",
    "        print(\"Shard \" + str(shard_id) + \" done after \" + str(int(time.time() - start)) + \"s\")\n",
    "        \n",
    "        save_embeddings_ds_to_parquet(embeddings, shard, output_folder + \"/part-\" + \"{:03d}\".format(shard_id) + \".parquet\")\n",
    "        print(\"Shard \" + str(shard_id) + \" saved after \" + str(int(time.time() - start)) + \"s\")\n",
    "\n",
    "\n",
    "def run_inference(tfrecords_folder, output_folder, batch_size=1000):\n",
    "    model = EfficientNetB0(weights='imagenet', include_top=False, pooling=\"avg\")\n",
    "    tfrecords_to_write_embeddings(tfrecords_folder, output_folder, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference(\"tfrecords\", \"embeddings\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pq.read_table(\"embeddings\").to_pandas()\n",
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image name:', str(embeddings['image_name'].iloc[0]), \n",
    "      '\\nEmbedding:', embeddings['embedding'].iloc[0], \n",
    "      '\\nLength of embedding:', len(embeddings['embedding'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbde62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c2edc5",
   "metadata": {},
   "source": [
    "#### Get images based on embedding similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn search\n",
    "def search(emb, k=5):\n",
    "    D, I = index.search(np.expand_dims(emb, 0), k)\n",
    "    return list(zip(D[0], [id_to_name[x] for x in I[0]]))\n",
    "\n",
    "\n",
    "# show original image\n",
    "def display_picture(image_name):\n",
    "    display(IPython.display.Image(filename=f\"{image_name}.jpeg\"))\n",
    "\n",
    "# show similar images\n",
    "def display_results(results):\n",
    "    hbox = HBox([VBox([widgets.Label(f\"{distance:.2f} {image_name}\"), widgets.Image(value=open(f\"{image_name}.jpeg\", 'rb').read())]) for distance, image_name in results])\n",
    "    display(hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {k:v.decode(\"utf-8\") for k,v in enumerate(list(embeddings[\"image_name\"]))}\n",
    "name_to_id = {v:k for k,v in id_to_name.items()}\n",
    "\n",
    "embeddings_stacked = np.stack(embeddings[\"embedding\"].to_numpy())\n",
    "xb = embeddings_stacked\n",
    "\n",
    "length_embedding = 1280\n",
    "index = faiss.IndexFlatIP(length_embedding)\n",
    "index.add(xb)\n",
    "\n",
    "image_id = np.random.randint(0, max(id_to_name.keys()))\n",
    "print(image_id, id_to_name[image_id])\n",
    "\n",
    "display_picture(id_to_name[image_id])\n",
    "display_results(search(xb[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d41efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
